#Speech Emotion Recognition
This Speech Emotion Recognition (SER) project focuses on classifying emotions from audio speech using deep learning. By leveraging publicly available datasets of emotional speech samples, the project integrates advanced audio preprocessing techniques and deep neural networks to identify emotions such as happy, sad, angry, neutral, and more. It depends solely on the emotion using the audio waves rather than words to classify sentiment. The datasets contain the exact same sentence in different emotions, which the model is able to classify.

##Datasets Used
The following datasets were employed for this project:

RAVDESS: Emotional speech and song data.

CREMA-D: Crowd-sourced multimodal emotional speech.

TESS: Toronto Emotional Speech Set.

SAVEE: Surrey Audio-Visual Expressed Emotion Dataset.
